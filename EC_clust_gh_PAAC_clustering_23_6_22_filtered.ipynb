{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using PseAAC features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u> Part 1: Extracting protein sequence data </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "class CAZy_data:\n",
    "    def __init__(self,filename1,filename2):\n",
    "        self.data,self.acc,self.seq=[],[],[]\n",
    "        with open(filename1,'r',encoding='utf-8') as inpt:\n",
    "            for each in inpt:\n",
    "                self.data.append(each.rstrip().split('$'))\n",
    "        with open(filename2,'r',encoding='utf-8') as inpt1:\n",
    "            for each1 in inpt1:\n",
    "                if each1.startswith('>'):\n",
    "                    self.acc.append(each1.rstrip())\n",
    "                else:\n",
    "                    self.seq.append(each1.rstrip())\n",
    "            \n",
    "                  \n",
    "    def data_fetch(self,typ,position):\n",
    "        typ_data=[]\n",
    "        if typ=='all':\n",
    "            typ_data=self.data\n",
    "        else:\n",
    "            for each in self.data:\n",
    "                mult=each[position].split(' ')\n",
    "                if len(mult)==1:#### In case typ = EC, Multi EC number and protein with no EC number are ignore.\n",
    "                    if mult[0]==typ:\n",
    "                        typ_data.append(each)\n",
    "        return typ_data\n",
    "    \n",
    "    def EC_GH(self,ec_no,gh_fam):\n",
    "        self.fasta=[]\n",
    "        cazy_ec=self.data_fetch(ec_no,1)\n",
    "        cazy_gh=self.data_fetch(gh_fam,-1)\n",
    "        self.common_data=[[i[0],i[1],i[3],i[4],i[-2],i[-1]] for i in cazy_ec if i in cazy_gh]\n",
    "        rm_prt, rm_prt_fasta=[],[]\n",
    "        for each in range(len(self.common_data)):\n",
    "            t=self.common_data[each]\n",
    "            if self.prtn_filter(t[0]):\n",
    "                all_acc=t[3].split(' ')\n",
    "                if all_acc[0]!='':\n",
    "                    for e_acc in all_acc:\n",
    "                        e_seq=self.seq_fetch(e_acc)\n",
    "                        try:\n",
    "                            create_error=0/len(e_seq) # to remove accession number which doesnt have hits\n",
    "                            self.fasta.append(f'>{e_acc}${t[0]}${t[1]}${t[2]}${t[-2]}${t[-1]}')\n",
    "                            self.fasta.append(e_seq[0])\n",
    "                        except ZeroDivisionError:\n",
    "                            rm_prt_fasta.append(e_acc)\n",
    "            else:\n",
    "                rm_prt.append(t)\n",
    "#         print('Total number of sequences:',len(self.fasta)/2)\n",
    "#         print('Number of removed partial or fragment proteins (CAZy):',len(rm_prt))\n",
    "#         print('Number of removed partial or fragment proteins (Fasta):',len(rm_prt_fasta))\n",
    "        return self.fasta,rm_prt,rm_prt_fasta\n",
    "    def prtn_filter(self,prt_name):\n",
    "        hit=1\n",
    "        if re.search('partial|fragment',prt_name.lower()):\n",
    "            hit-=1\n",
    "        return hit\n",
    "            \n",
    "    def seq_fetch(self,accession):\n",
    "        hits=[]\n",
    "        temp=0\n",
    "        for each in range(len(self.acc)):\n",
    "            if re.search(f'{accession}\\D',self.acc[each]):\n",
    "                temp+=1\n",
    "                \n",
    "                if self.prtn_filter(self.acc[each]): # remove partial| fragment accession numbers from GenBank description\n",
    "                    hits.append(self.seq[each])\n",
    "        if temp>1:\n",
    "            print(f'Multiple hits for {accession}')\n",
    "        elif temp==0:\n",
    "            print(f'No hits for {accession}')\n",
    "        return hits\n",
    "     \n",
    "In_data=CAZy_data('D:/After_4_4_22/data/CAZy_23_6_22/cazy_char_10_6_22.txt','D:/After_4_4_22/data/CAZy_23_6_22/char_gh_23_6_22.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u> Part 2: Extracting feature from protein sequences </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# 1: Hydrophobicity, 2: Hydrophilicity, 3: mass, 4: pk1, 5:pk2, 6:pi, 20: 14 scale, 60: Tanford\n",
    "class Standard_values:\n",
    "    def __init__(self,filename):\n",
    "        self.data=[]\n",
    "        with open(filename,'r') as inpt:\n",
    "            for each in inpt:\n",
    "                self.data.append(each.rstrip().split(','))\n",
    "        del self.data[0]\n",
    "        \n",
    "    def get_prop(self,prop):\n",
    "        got_prop,amino_acid={},{}\n",
    "        for each in prop:\n",
    "            got_prop[each]=self.properties(each)\n",
    "        d=1\n",
    "        for each in got_prop[1].keys():\n",
    "            amino_acid[d]=each\n",
    "            d+=1\n",
    "        return amino_acid,got_prop\n",
    "    \n",
    "    def properties(self, val):\n",
    "        temp,norm={},{}\n",
    "        for each in self.data:\n",
    "            temp[each[0]]=float(each[val])\n",
    "        relative=stats.zscore(np.array(list(temp.values())))\n",
    "        for a,b in zip(temp.keys(),relative):\n",
    "            norm[a]=b\n",
    "        return norm\n",
    "\n",
    "class Sequence:\n",
    "    def __init__(self,filename):\n",
    "        self.data=[]\n",
    "        if type(filename)==str:\n",
    "            with open(filename,'r') as inpt:\n",
    "                for each in inpt:\n",
    "                    self.data.append(each.rstrip())\n",
    "        else:\n",
    "            self.data=filename\n",
    "                       \n",
    "    def output(self):\n",
    "        a,s,l=[],[],[]\n",
    "        unusual=0\n",
    "        for ele in self.ml_sl():\n",
    "            if ele.startswith('>'):\n",
    "                a.append(ele)\n",
    "            else:\n",
    "                if re.search('[UZOBJX]',ele.upper()):\n",
    "#                     print(a[-1])\n",
    "                    del a[-1]\n",
    "                    unusual+=1\n",
    "                    continue\n",
    "                l.append(len(ele))\n",
    "                s.append(ele.upper())\n",
    "#         print('The length of the smallest sequence:',min(l))\n",
    "#         print('Sequence with \"X\" present:',unusual)\n",
    "        return a,s,l,unusual\n",
    "             \n",
    "    def ml_sl(self):\n",
    "        acc_seq=[]\n",
    "        for k in range(len(self.data)):\n",
    "            if self.data[k].startswith('>'):\n",
    "                acc_seq.append(self.data[k])\n",
    "                join_=0\n",
    "                for l in range(k+1,len(self.data)):\n",
    "                    if self.data[l].startswith('>') == False:\n",
    "                        join_+=1\n",
    "                    else:\n",
    "                        break\n",
    "                acc_seq.append(''.join(self.data[k+1:k+1+join_]))\n",
    "        return acc_seq\n",
    "\n",
    "class Pseaac:\n",
    "    def __init__(self,filename):\n",
    "        self.filename=filename\n",
    "    def collect(self,lamb,w,pro,nf):\n",
    "        val=[]\n",
    "        val.append(['#']+[ea for ea in keys.values()]+['\\u03BB'+str(eac+1) for eac in range(lamb)])\n",
    "        for e_seq in range(len(seq)):# single sequence taken for test\n",
    "            q=self.pse(seq[e_seq],lamb,w,pro,nf)\n",
    "            tem=acc[e_seq].split(' ')[0][1:]\n",
    "            val.append([acc[e_seq]]+q)\n",
    "        df=pd.DataFrame(val[1:],columns=val[0])\n",
    "#         print('PseAAC feature have been extracted!!!')\n",
    "        return df\n",
    "        \n",
    "    def pse(self,data,lamb,w,pro,nf):\n",
    "        thet=self.theta(data,lamb,pro)\n",
    "        deno=1+(w*sum(thet.values()))\n",
    "        p=[]\n",
    "        if nf==1:\n",
    "            norm=(len(data))\n",
    "        else:\n",
    "            norm=1\n",
    "        for u in range(1,21+lamb):\n",
    "            if u>=1 and u<=20:\n",
    "    #             print(u,'natural')\n",
    "                num=data.count(keys[u])/norm # frequency\n",
    "                p.append(num/deno)\n",
    "            elif u>=21 and u<=20+lamb:\n",
    "    #             print(u,'pseudo')\n",
    "                num=w*thet[u-20]\n",
    "                p.append(num/deno)\n",
    "        return p\n",
    "    \n",
    "    def theta(self,data,lamb,pro):\n",
    "        the={}\n",
    "        for u in range(1,lamb+1):\n",
    "            the[u]=(1/(len(data)-u))*self.rel_cal(data,u,pro)\n",
    "        return the\n",
    "    \n",
    "    def rel_cal(self,data,v,pro):\n",
    "        tem=[]\n",
    "        for u in range(len(data)-v):\n",
    "            te=[]\n",
    "            for u1 in pro:\n",
    "                x=((values[u1][data[u]])-(values[u1][data[u+v]]))**2\n",
    "                te.append(x)\n",
    "    #             print(u1,u,u+v,data[u],data[u+v],x)\n",
    "            tem.append(sum(te)/len(pro))\n",
    "        return sum(tem)\n",
    "\n",
    "keys,values=Standard_values('D:/After_4_4_22/data/CAZy_23_6_22/7_98_hydrophobicity.csv').get_prop([1,2,3,4,5,6,20,60])\n",
    "# pseaac_data['Length']=stats.zscore(min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Clustering Algorithm'''\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, mixture, manifold, decomposition, preprocessing,metrics\n",
    "import random\n",
    "from collections import Counter,defaultdict\n",
    "import copy\n",
    "\n",
    "class clustering:\n",
    "    rs=77\n",
    "#     rn=random.randint(1,99)\n",
    "    def __init__(self,folder,data,n,cat):\n",
    "        self.x=data.iloc[:,1:].values\n",
    "        self.y=data.iloc[:,0]\n",
    "        self.folder=folder\n",
    "        self.cat=cat\n",
    "        self.anno_label={0:'acc',1:'prtn',2:'ec',3:'org',4:'species',5:'ghf'}\n",
    "        temp=[i.split('$')[cat[0]] for i in self.y]\n",
    "        lab=list(set(temp))\n",
    "        self.true_lab=[lab.index(j) for j in temp]\n",
    "        try:\n",
    "            n.isalpha()\n",
    "            self.n=len(lab)\n",
    "        except AttributeError:\n",
    "            self.n=n\n",
    "        self.temp1=','.join([f'{k}:{v}' for k,v in dict(Counter(temp)).items()])\n",
    "        \n",
    "    def kmeans(self):\n",
    "        start = time.time()\n",
    "        self.names = 'km'\n",
    "        kmeans = cluster.KMeans(n_clusters=self.n,random_state=clustering.rs) # Number of clusters\n",
    "        self.labels = kmeans.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def affinity(self):\n",
    "        start = time.time()\n",
    "        self.names = 'apc'\n",
    "        apc = cluster.AffinityPropagation(random_state=clustering.rs)\n",
    "        self.labels = apc.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def meanshift(self):\n",
    "        start = time.time()\n",
    "        self.names = 'ms'\n",
    "        ms = cluster.MeanShift()\n",
    "        self.labels = ms.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def spectral(self):\n",
    "        start = time.time()\n",
    "        self.names = 'spec'\n",
    "        spectral = cluster.SpectralClustering(n_clusters=self.n,assign_labels=\"discretize\",random_state=clustering.rs) # Number of clusters\n",
    "        self.labels = spectral.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def agglomerative(self):\n",
    "        start = time.time()\n",
    "        self.names = 'agglo'\n",
    "        agglo = cluster.AgglomerativeClustering(n_clusters=self.n) # Number of clusters\n",
    "        self.labels = agglo.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def dbscan(self):\n",
    "        start = time.time()\n",
    "        self.names = 'dbs'\n",
    "        new_x=preprocessing.StandardScaler().fit_transform(self.x)\n",
    "        dbs = cluster.DBSCAN()\n",
    "        self.labels = dbs.fit_predict(new_x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def optics(self):\n",
    "        start = time.time()\n",
    "        self.names = 'opt'\n",
    "        opt = cluster.OPTICS()\n",
    "        self.labels = opt.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def gaussian(self):\n",
    "        start = time.time()\n",
    "        self.names = 'gm'\n",
    "        gm = mixture.GaussianMixture(n_components=self.n,random_state=clustering.rs) # Number of Clusters\n",
    "        self.labels = gm.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "        \n",
    "    def birch(self):\n",
    "        start = time.time()\n",
    "        self.names = 'bir'\n",
    "        brc = cluster.Birch() # Number of clusters\n",
    "        self.labels = brc.fit_predict(self.x)\n",
    "        end = time.time()\n",
    "        self.t = round((end-start),3)\n",
    "        return self.label_save()\n",
    "\n",
    "    def label_save(self):\n",
    "        dfout = pd.DataFrame({'Accession': self.y,  'predicted': self.labels, 'expected':self.true_lab})\n",
    "        try:\n",
    "            os.mkdir(self.folder)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        dfout.to_csv(f'{self.folder}\\ML_{self.names}_{len(set(self.labels))}.txt',sep='\\t', index=False)\n",
    "        self.file()\n",
    "        return self.analysis()\n",
    "    \n",
    "    def analysis(self):\n",
    "        value=metrics.fowlkes_mallows_score(self.true_lab,self.labels)\n",
    "        tot_val=[self.names,self.anno_label[self.cat[0]],str(lambda_value),str(round(value,3)),str(self.n),str(len(set(self.labels))),self.temp1,str(len(self.true_lab))]\n",
    "        return tot_val\n",
    "    \n",
    "    def file(self):\n",
    "        try:\n",
    "            os.mkdir(f'{self.folder}/table')\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        dd=defaultdict(list)\n",
    "        for i in range(len(self.labels)):\n",
    "            dd[self.labels[i]].append(self.y[i])\n",
    "        self.excel(dict(sorted(dd.items())))\n",
    "        \n",
    "    def excel(self,anno):\n",
    "        all_anno={}\n",
    "        for i in self.cat:\n",
    "            temp={}\n",
    "            for j,k in anno.items():\n",
    "                te=[]\n",
    "                for l in k:\n",
    "                    te.append(l.split('$')[i])\n",
    "                temp[j]=dict(Counter(te))\n",
    "            df=pd.DataFrame(temp).fillna(0).astype(int)\n",
    "            df.loc['Total']=df.sum(axis=0)\n",
    "            df.loc[:,'Total']=df.sum(axis=1)\n",
    "            df.to_excel(f'{self.folder}/table/{self.names}_{len(set(self.labels))}_{self.anno_label[i]}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_filter:\n",
    "    def __init__(self,ac,se):\n",
    "        self.ac=ac\n",
    "        self.se=se\n",
    "    def present_absent(self,typ,data):\n",
    "        print('Filter has been applied....')\n",
    "        new_acc,new_seq=[],[]\n",
    "        not_acc,not_seq=[],[]\n",
    "        for i in range(len(self.ac)):\n",
    "            if self.ac[i].split('$')[-1] in data:\n",
    "                new_acc.append(self.ac[i])\n",
    "                new_seq.append(self.se[i])\n",
    "            else:\n",
    "                not_acc.append(self.ac[i])\n",
    "                not_seq.append(self.se[i])\n",
    "        if typ=='present':\n",
    "            return new_acc,new_seq\n",
    "        elif typ=='absent':\n",
    "            return not_acc,not_seq\n",
    "        else:\n",
    "            print('Check the spelling!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hits for NP_126623.1\n",
      "No hits for NP_143072.1\n",
      "No hits for AAU23613.1\n",
      "No hits for NP_389695.1\n",
      "No hits for NP_622045.1\n",
      "No hits for CAB01405.1\n",
      "No hits for ABZ70413.1\n",
      "No hits for AAD48494.2\n",
      "No hits for NP_241469.1\n",
      "No hits for WP_018063499.1\n",
      "No hits for AAC02964.1\n",
      "No hits for BAA12826.1\n",
      "No hits for AAZ56745.1\n",
      "No hits for AAZ54939.1\n",
      "No hits for AHA42547.1\n",
      "No hits for NP_638867.1\n",
      "No hits for NP_298108.1\n",
      "No hits for XP_324942.1\n",
      "No hits for XP_002475436.1\n",
      "No hits for AAL33630.1\n",
      "No hits for AAL33639.1\n",
      "No hits for CAA16243.1\n",
      "No hits for CAE55238.1\n",
      "No hits for NP_214576.1\n",
      "No hits for AAZ55112.1\n",
      "No hits for BAB64564.1\n",
      "No hits for BAB64563.1\n",
      "No hits for XP_366456.1\n",
      "No hits for XP_366456.2\n",
      "No hits for NP_213966.1\n",
      "No hits for NP_347552.1\n",
      "No hits for YP_003844202.1\n",
      "No hits for AAZ55662.1\n",
      "No hits for AAA27397.1\n",
      "No hits for AAZ56209.1\n",
      "No hits for EFA05721.1\n",
      "No hits for XP_001810693.1\n",
      "No hits for NP_578583.1\n",
      "No hits for CAC24331.1\n",
      "No hits for NP_343873.1\n",
      "No hits for NP_342800.1\n",
      "No hits for NP_229324.1\n",
      "No hits for NP_229325.1\n",
      "No hits for XP_391213.1\n",
      "No hits for XP_388068.1\n",
      "No hits for XP_383205.1\n",
      "No hits for XP_324478.1\n",
      "No hits for NP_228117.1\n",
      "Sequence has been collected for 3.2.1.4....\n",
      "Filter has been applied....\n",
      "Feature has been extracted for 3.2.1.4....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_birch.py:647: ConvergenceWarning: Number of subclusters found (1) by Birch is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering has been done for 3.2.1.4....\n",
      "No hits for NP_126623.1\n",
      "No hits for NP_143072.1\n",
      "No hits for AAU23613.1\n",
      "No hits for NP_389695.1\n",
      "No hits for NP_622045.1\n",
      "No hits for CAB01405.1\n",
      "No hits for ABZ70413.1\n",
      "No hits for AAD48494.2\n",
      "No hits for NP_241469.1\n",
      "No hits for WP_018063499.1\n",
      "No hits for AAC02964.1\n",
      "No hits for BAA12826.1\n",
      "No hits for AAZ56745.1\n",
      "No hits for AAZ54939.1\n",
      "No hits for AHA42547.1\n",
      "No hits for NP_638867.1\n",
      "No hits for NP_298108.1\n",
      "No hits for XP_324942.1\n",
      "No hits for XP_002475436.1\n",
      "No hits for AAL33630.1\n",
      "No hits for AAL33639.1\n",
      "No hits for CAA16243.1\n",
      "No hits for CAE55238.1\n",
      "No hits for NP_214576.1\n",
      "No hits for AAZ55112.1\n",
      "No hits for BAB64564.1\n",
      "No hits for BAB64563.1\n",
      "No hits for XP_366456.1\n",
      "No hits for XP_366456.2\n",
      "No hits for NP_213966.1\n",
      "No hits for NP_347552.1\n",
      "No hits for YP_003844202.1\n",
      "No hits for AAZ55662.1\n",
      "No hits for AAA27397.1\n",
      "No hits for AAZ56209.1\n",
      "No hits for EFA05721.1\n",
      "No hits for XP_001810693.1\n",
      "No hits for NP_578583.1\n",
      "No hits for CAC24331.1\n",
      "No hits for NP_343873.1\n",
      "No hits for NP_342800.1\n",
      "No hits for NP_229324.1\n",
      "No hits for NP_229325.1\n",
      "No hits for XP_391213.1\n",
      "No hits for XP_388068.1\n",
      "No hits for XP_383205.1\n",
      "No hits for XP_324478.1\n",
      "No hits for NP_228117.1\n",
      "Sequence has been collected for 3.2.1.4....\n",
      "Filter has been applied....\n",
      "Feature has been extracted for 3.2.1.4....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_birch.py:647: ConvergenceWarning: Number of subclusters found (1) by Birch is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering has been done for 3.2.1.4....\n",
      "No hits for NP_126623.1\n",
      "No hits for NP_143072.1\n",
      "No hits for AAU23613.1\n",
      "No hits for NP_389695.1\n",
      "No hits for NP_622045.1\n",
      "No hits for CAB01405.1\n",
      "No hits for ABZ70413.1\n",
      "No hits for AAD48494.2\n",
      "No hits for NP_241469.1\n",
      "No hits for WP_018063499.1\n",
      "No hits for AAC02964.1\n",
      "No hits for BAA12826.1\n",
      "No hits for AAZ56745.1\n",
      "No hits for AAZ54939.1\n",
      "No hits for AHA42547.1\n",
      "No hits for NP_638867.1\n",
      "No hits for NP_298108.1\n",
      "No hits for XP_324942.1\n",
      "No hits for XP_002475436.1\n",
      "No hits for AAL33630.1\n",
      "No hits for AAL33639.1\n",
      "No hits for CAA16243.1\n",
      "No hits for CAE55238.1\n",
      "No hits for NP_214576.1\n",
      "No hits for AAZ55112.1\n",
      "No hits for BAB64564.1\n",
      "No hits for BAB64563.1\n",
      "No hits for XP_366456.1\n",
      "No hits for XP_366456.2\n",
      "No hits for NP_213966.1\n",
      "No hits for NP_347552.1\n",
      "No hits for YP_003844202.1\n",
      "No hits for AAZ55662.1\n",
      "No hits for AAA27397.1\n",
      "No hits for AAZ56209.1\n",
      "No hits for EFA05721.1\n",
      "No hits for XP_001810693.1\n",
      "No hits for NP_578583.1\n",
      "No hits for CAC24331.1\n",
      "No hits for NP_343873.1\n",
      "No hits for NP_342800.1\n",
      "No hits for NP_229324.1\n",
      "No hits for NP_229325.1\n",
      "No hits for XP_391213.1\n",
      "No hits for XP_388068.1\n",
      "No hits for XP_383205.1\n",
      "No hits for XP_324478.1\n",
      "No hits for NP_228117.1\n",
      "Sequence has been collected for 3.2.1.4....\n",
      "Filter has been applied....\n",
      "Feature has been extracted for 3.2.1.4....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_birch.py:647: ConvergenceWarning: Number of subclusters found (1) by Birch is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering has been done for 3.2.1.4....\n",
      "No hits for NP_126623.1\n",
      "No hits for NP_143072.1\n",
      "No hits for AAU23613.1\n",
      "No hits for NP_389695.1\n",
      "No hits for NP_622045.1\n",
      "No hits for CAB01405.1\n",
      "No hits for ABZ70413.1\n",
      "No hits for AAD48494.2\n",
      "No hits for NP_241469.1\n",
      "No hits for WP_018063499.1\n",
      "No hits for AAC02964.1\n",
      "No hits for BAA12826.1\n",
      "No hits for AAZ56745.1\n",
      "No hits for AAZ54939.1\n",
      "No hits for AHA42547.1\n",
      "No hits for NP_638867.1\n",
      "No hits for NP_298108.1\n",
      "No hits for XP_324942.1\n",
      "No hits for XP_002475436.1\n",
      "No hits for AAL33630.1\n",
      "No hits for AAL33639.1\n",
      "No hits for CAA16243.1\n",
      "No hits for CAE55238.1\n",
      "No hits for NP_214576.1\n",
      "No hits for AAZ55112.1\n",
      "No hits for BAB64564.1\n",
      "No hits for BAB64563.1\n",
      "No hits for XP_366456.1\n",
      "No hits for XP_366456.2\n",
      "No hits for NP_213966.1\n",
      "No hits for NP_347552.1\n",
      "No hits for YP_003844202.1\n",
      "No hits for AAZ55662.1\n",
      "No hits for AAA27397.1\n",
      "No hits for AAZ56209.1\n",
      "No hits for EFA05721.1\n",
      "No hits for XP_001810693.1\n",
      "No hits for NP_578583.1\n",
      "No hits for CAC24331.1\n",
      "No hits for NP_343873.1\n",
      "No hits for NP_342800.1\n",
      "No hits for NP_229324.1\n",
      "No hits for NP_229325.1\n",
      "No hits for XP_391213.1\n",
      "No hits for XP_388068.1\n",
      "No hits for XP_383205.1\n",
      "No hits for XP_324478.1\n",
      "No hits for NP_228117.1\n",
      "Sequence has been collected for 3.2.1.4....\n",
      "Filter has been applied....\n",
      "Feature has been extracted for 3.2.1.4....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_birch.py:647: ConvergenceWarning: Number of subclusters found (1) by Birch is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering has been done for 3.2.1.4....\n",
      "No hits for NP_126623.1\n",
      "No hits for NP_143072.1\n",
      "No hits for AAU23613.1\n",
      "No hits for NP_389695.1\n",
      "No hits for NP_622045.1\n",
      "No hits for CAB01405.1\n",
      "No hits for ABZ70413.1\n",
      "No hits for AAD48494.2\n",
      "No hits for NP_241469.1\n",
      "No hits for WP_018063499.1\n",
      "No hits for AAC02964.1\n",
      "No hits for BAA12826.1\n",
      "No hits for AAZ56745.1\n",
      "No hits for AAZ54939.1\n",
      "No hits for AHA42547.1\n",
      "No hits for NP_638867.1\n",
      "No hits for NP_298108.1\n",
      "No hits for XP_324942.1\n",
      "No hits for XP_002475436.1\n",
      "No hits for AAL33630.1\n",
      "No hits for AAL33639.1\n",
      "No hits for CAA16243.1\n",
      "No hits for CAE55238.1\n",
      "No hits for NP_214576.1\n",
      "No hits for AAZ55112.1\n",
      "No hits for BAB64564.1\n",
      "No hits for BAB64563.1\n",
      "No hits for XP_366456.1\n",
      "No hits for XP_366456.2\n",
      "No hits for NP_213966.1\n",
      "No hits for NP_347552.1\n",
      "No hits for YP_003844202.1\n",
      "No hits for AAZ55662.1\n",
      "No hits for AAA27397.1\n",
      "No hits for AAZ56209.1\n",
      "No hits for EFA05721.1\n",
      "No hits for XP_001810693.1\n",
      "No hits for NP_578583.1\n",
      "No hits for CAC24331.1\n",
      "No hits for NP_343873.1\n",
      "No hits for NP_342800.1\n",
      "No hits for NP_229324.1\n",
      "No hits for NP_229325.1\n",
      "No hits for XP_391213.1\n",
      "No hits for XP_388068.1\n",
      "No hits for XP_383205.1\n",
      "No hits for XP_324478.1\n",
      "No hits for NP_228117.1\n",
      "Sequence has been collected for 3.2.1.4....\n",
      "Filter has been applied....\n",
      "Feature has been extracted for 3.2.1.4....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "c:\\users\\rakes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_birch.py:647: ConvergenceWarning: Number of subclusters found (1) by Birch is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering has been done for 3.2.1.4....\n",
      "Mission completed in 245.445 seconds\n"
     ]
    }
   ],
   "source": [
    "t1=time.perf_counter()\n",
    "total_data=[]\n",
    "total_rm_cazy,total_rm_genbank={},{}\n",
    "value_error,no_entry=[],[]\n",
    "for xx in [4,5,6,7,8]:\n",
    "    each='3.2.1.4'\n",
    "    ec_number=each\n",
    "    gh_family='all'\n",
    "    cazy_acc_seq,rm_cazy,rm_genbank=In_data.EC_GH(ec_number,gh_family) # write all to fetch all the EC number or all the GH family\n",
    "    total_rm_cazy[each],total_rm_genbank[each]=rm_cazy,rm_genbank\n",
    "    acc,seq,min_len,x_aa=Sequence(cazy_acc_seq).output()\n",
    "    print(f'Sequence has been collected for {each}....')\n",
    "#     Filtered applied\n",
    "\n",
    "    acc,seq=add_filter(acc,seq).present_absent('present',['GH5','GH9','GH12','GH45'])\n",
    "    \n",
    "    min_lamb=30\n",
    "    try:\n",
    "        if min(min_len)<min_lamb:\n",
    "            lambda_value=min(min_len)\n",
    "        else:\n",
    "            lambda_value=min_lamb\n",
    "    except ValueError:\n",
    "        print(each,': doesnt have sequences')\n",
    "        no_entry.append(each)\n",
    "        continue\n",
    "    pseaac_data=Pseaac(f'PAAC_{ec_number}_{gh_family}_L{lambda_value}.txt').collect(lambda_value,0.05,[60,2,3],1)\n",
    "    print(f'Feature has been extracted for {each}....')\n",
    "    ec_=ec_number.replace('.','_')\n",
    "    # In the below statement 'auto' means it takes automatic clusters based on number labels given, you can also choose any number.\n",
    "    clust=clustering(f'Filtered_{gh_family}_{ec_}_{xx}',pseaac_data,xx,[5]) # 0:'acc',1:'prtn',2:'ec',3:'org',4:'species',5:'ghf'\n",
    "    try:\n",
    "        km=clust.kmeans()\n",
    "        apc=clust.affinity()\n",
    "        ms=clust.meanshift()\n",
    "        spec=clust.spectral()\n",
    "        agglo=clust.agglomerative()\n",
    "        dbs=clust.dbscan()\n",
    "        opt=clust.optics()\n",
    "        gm=clust.gaussian()\n",
    "        bir=clust.birch()\n",
    "    except ValueError:\n",
    "        print(f'{each} has {len(acc)} samples which is less than 5 min_samples ')\n",
    "        value_error.append([each,len(acc)])\n",
    "        continue\n",
    "    print(f'Clustering has been done for {each}....')\n",
    "    all_clust={'km':km,'apc':apc,'ms':ms,'spec':spec,'agglo':agglo,'dbs':dbs,'opt':opt,'gm':gm,'bir':bir}\n",
    "    for aa in all_clust.values():\n",
    "        bb=[each]+aa+[str(len(rm_cazy)),str(len(rm_genbank))]+[str(x_aa)]\n",
    "        total_data.append('$'.join(bb))\n",
    "t2=time.perf_counter()\n",
    "print('Mission completed in',round(t2-t1,3),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "titl=['EC_number','Method','label_type','lambda','FMI','ex_groups','pred_groups','distribution','total','CAZy_partial','Fasta_partial','X_aa']\n",
    "outpt=open('filtered_ghf_number_cluster_ec.txt','w')\n",
    "outpt.write('$'.join(titl)+'\\n')\n",
    "for line in tqdm(total_data):\n",
    "    outpt.write(line+'\\n')\n",
    "outpt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
